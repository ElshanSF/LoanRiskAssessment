{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Clear namespace\n",
    "for name in dir():\n",
    "    if not name.startswith('_'):\n",
    "        del globals()[name]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Install package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#!pip install pydotplus"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Import libraries before starting\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn import tree\n",
    "import pandas as pd\n",
    "#import pydotplus\n",
    "import seaborn as sns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Functions (necessary for the following calculations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#--------  display_dt\n",
    "# Print decision tree model 'model', already fitted\n",
    "# Input: \n",
    "#      model     (Decision tree model)\n",
    "# Returns: \n",
    "#      None\n",
    "\n",
    "def display_dt(model):\n",
    "    dummy_io = StringIO() \n",
    "    tree.export_graphviz(dt, out_file = dummy_io) \n",
    "    print( dummy_io.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#--------  print_tree\n",
    "# This function creates images of tree models using pydotplus\n",
    "# Input: \n",
    "#      estimator   (Decision tree model)\n",
    "#      features    (Decision tree features)\n",
    "#      class_names (Names of the classes)\n",
    "# Returns: \n",
    "#      graph     (Decision tree graph )\n",
    "# Source:\n",
    "#      https://github.com/JWarmenhoven/ISLR-python\n",
    "\n",
    "from io import StringIO\n",
    "def print_tree(estimator, features, class_names=None, filled=True):\n",
    "    tree = estimator\n",
    "    names = features\n",
    "    color = filled\n",
    "    classn = class_names\n",
    "    \n",
    "    dot_data = StringIO.StringIO()\n",
    "    export_graphviz(estimator, out_file=dot_data, feature_names=features, proportion=True, class_names=classn, filled=filled)\n",
    "    graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "    return(graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Code here\n",
    "# Load the training data\n",
    "train_data = np.loadtxt('dataset_5_train.txt', delimiter=',')\n",
    "\n",
    "# Load the test data\n",
    "test_data = np.loadtxt('dataset_5_test.txt', delimiter=',')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### First look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Shape: (250, 25)\n",
      "Test Data Shape: (9750, 25)\n",
      "\n",
      "Train Data - First Few Rows:\n",
      "       0         1    2    3    4     5    6    7    8    9   ...       15  \\\n",
      "0  3288.0   20000.0  2.0  1.0  2.0  39.0  0.0  0.0  0.0  0.0  ...  19308.0   \n",
      "1  3001.0   50000.0  1.0  2.0  2.0  27.0  2.0  2.0  0.0  0.0  ...   7382.0   \n",
      "2  3288.0   80000.0  1.0  2.0  2.0  27.0  1.0  2.0  2.0  2.0  ...  68531.0   \n",
      "3  3652.0   70000.0  2.0  2.0  2.0  22.0  0.0  0.0  0.0  0.0  ...  69316.0   \n",
      "4  3817.0  200000.0  1.0  1.0  2.0  24.0 -1.0 -1.0 -1.0 -1.0  ...  18154.0   \n",
      "\n",
      "        16       17      18      19       20      21       22       23   24  \n",
      "0  19498.0      0.0  1588.0  1770.0   1200.0   390.0      0.0  44334.0  1.0  \n",
      "1   1975.0  50514.0  4146.0  1200.0      0.0     0.0  49800.0      0.0  1.0  \n",
      "2  69808.0  70544.0  5000.0  3100.0   2000.0  3000.0   2000.0   4000.0  1.0  \n",
      "3  29083.0  28140.0  3200.0  3600.0   3075.0  1204.0   1200.0   1046.0  0.0  \n",
      "4  13677.0   2018.0   200.0   198.0  18156.0     0.0   1150.0      0.0  0.0  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "\n",
      "Test Data - First Few Rows:\n",
      "       0         1    2    3    4     5    6    7    8    9   ...       15  \\\n",
      "0  3652.0  210000.0  2.0  3.0  1.0  28.0  0.0  0.0  0.0  0.0  ...  41084.0   \n",
      "1  3662.0  110000.0  2.0  3.0  1.0  55.0 -1.0  2.0  0.0  0.0  ...   5819.0   \n",
      "2  3530.0   70000.0  1.0  3.0  1.0  45.0  2.0  2.0  2.0  2.0  ...  67338.0   \n",
      "3  3827.0  130000.0  1.0  1.0  1.0  40.0  2.0  2.0  0.0  0.0  ...  86407.0   \n",
      "4  3288.0  710000.0  2.0  2.0  1.0  40.0 -2.0 -2.0 -2.0 -1.0  ...   1004.0   \n",
      "\n",
      "        16       17      18      19      20      21       22      23   24  \n",
      "0  42416.0  43707.0  2000.0  2000.0  2000.0  2000.0   2000.0  2000.0  0.0  \n",
      "1   4807.0   5579.0     0.0  1087.0  1532.0     0.0   1000.0     0.0  1.0  \n",
      "2  70769.0  68957.0  3100.0  3008.0     0.0  5100.0   2600.0     0.0  1.0  \n",
      "3  88959.0  97487.0     0.0  5000.0  5000.0  4000.0  10000.0  3724.0  1.0  \n",
      "4    854.0   8626.0     0.0     0.0  1004.0     0.0   8000.0  5000.0  1.0  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.DataFrame(train_data)\n",
    "test_df = pd.DataFrame(test_data)\n",
    "\n",
    "# Check the shape of the datasets\n",
    "print(\"Train Data Shape:\", train_df.shape)\n",
    "print(\"Test Data Shape:\", test_df.shape)\n",
    "\n",
    "# Check the first few rows of the datasets\n",
    "print(\"\\nTrain Data - First Few Rows:\")\n",
    "print(train_df.head())\n",
    "\n",
    "print(\"\\nTest Data - First Few Rows:\")\n",
    "print(test_df.head())\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "###Data cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Values - Train Data:\n",
      "0     0\n",
      "1     0\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "5     0\n",
      "6     0\n",
      "7     0\n",
      "8     0\n",
      "9     0\n",
      "10    0\n",
      "11    0\n",
      "12    0\n",
      "13    0\n",
      "14    0\n",
      "15    0\n",
      "16    0\n",
      "17    0\n",
      "18    0\n",
      "19    0\n",
      "20    0\n",
      "21    0\n",
      "22    0\n",
      "23    0\n",
      "24    0\n",
      "dtype: int64\n",
      "\n",
      "Missing Values - Test Data:\n",
      "0     0\n",
      "1     0\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "5     0\n",
      "6     0\n",
      "7     0\n",
      "8     0\n",
      "9     0\n",
      "10    0\n",
      "11    0\n",
      "12    0\n",
      "13    0\n",
      "14    0\n",
      "15    0\n",
      "16    0\n",
      "17    0\n",
      "18    0\n",
      "19    0\n",
      "20    0\n",
      "21    0\n",
      "22    0\n",
      "23    0\n",
      "24    0\n",
      "dtype: int64\n",
      "\n",
      "Data Types - Train Data:\n",
      "0     float64\n",
      "1     float64\n",
      "2     float64\n",
      "3     float64\n",
      "4     float64\n",
      "5     float64\n",
      "6     float64\n",
      "7     float64\n",
      "8     float64\n",
      "9     float64\n",
      "10    float64\n",
      "11    float64\n",
      "12    float64\n",
      "13    float64\n",
      "14    float64\n",
      "15    float64\n",
      "16    float64\n",
      "17    float64\n",
      "18    float64\n",
      "19    float64\n",
      "20    float64\n",
      "21    float64\n",
      "22    float64\n",
      "23    float64\n",
      "24    float64\n",
      "dtype: object\n",
      "\n",
      "Data Types - Test Data:\n",
      "0     float64\n",
      "1     float64\n",
      "2     float64\n",
      "3     float64\n",
      "4     float64\n",
      "5     float64\n",
      "6     float64\n",
      "7     float64\n",
      "8     float64\n",
      "9     float64\n",
      "10    float64\n",
      "11    float64\n",
      "12    float64\n",
      "13    float64\n",
      "14    float64\n",
      "15    float64\n",
      "16    float64\n",
      "17    float64\n",
      "18    float64\n",
      "19    float64\n",
      "20    float64\n",
      "21    float64\n",
      "22    float64\n",
      "23    float64\n",
      "24    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in the datasets\n",
    "print(\"\\nMissing Values - Train Data:\")\n",
    "print(train_df.isnull().sum())\n",
    "\n",
    "print(\"\\nMissing Values - Test Data:\")\n",
    "print(test_df.isnull().sum())\n",
    "\n",
    "# Check the data types of the columns\n",
    "print(\"\\nData Types - Train Data:\")\n",
    "print(train_df.dtypes)\n",
    "\n",
    "print(\"\\nData Types - Test Data:\")\n",
    "print(test_df.dtypes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Prepare data for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaned Train Data shape:\n",
      "(250, 25)\n",
      "\n",
      "Cleaned Test Data shape:\n",
      "(9750, 25)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Eliminate null values by removing rows with missing values\n",
    "train_data_clean = train_data[~np.isnan(train_data).any(axis=1)]\n",
    "test_data_clean = test_data[~np.isnan(test_data).any(axis=1)]\n",
    "\n",
    "print(\"\\nCleaned Train Data shape:\")\n",
    "print(train_data_clean.shape)\n",
    "\n",
    "print(\"\\nCleaned Test Data shape:\")\n",
    "print(test_data_clean.shape)\n",
    "#X_train = train_data[:, :-1]  # Features\n",
    "#y_train = train_data[:, -1]   # Target variable\n",
    "\n",
    "# Separate the features (attributes) and the target variable for the test data\n",
    "#X_test = test_data[:, :-1]    # Features\n",
    "#y_test = test_data[:, -1]     # Target variable"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8306666666666667\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Convert cleaned train and test data to DataFrames\n",
    "train_data_clean = pd.DataFrame(train_data_clean)\n",
    "test_data_clean = pd.DataFrame(test_data_clean)\n",
    "\n",
    "# Assign column names to train and test data\n",
    "train_data_clean.columns = ['feature_' + str(i) for i in range(25)]\n",
    "test_data_clean.columns = ['feature_' + str(i) for i in range(25)]\n",
    "\n",
    "# Split the cleaned data into input features and labels\n",
    "try: \n",
    "    X_train = train_data_clean.drop(columns=['feature_24'])\n",
    "    y_train = train_data_clean['feature_24']\n",
    "except: \n",
    "    pass\n",
    "\n",
    "# Create a Decision Tree Classifier\n",
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "# Train the model\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Predict labels for test data\n",
    "X_test = test_data_clean.drop(columns=['feature_24'])\n",
    "y_test = test_data_clean['feature_24']\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = (y_pred == y_test).mean()\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pydotplus'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[13], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtree\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m export_graphviz\n\u001B[1;32m----> 2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpydotplus\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mIPython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdisplay\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Image\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m# Define the feature names\u001B[39;00m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'pydotplus'"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "from IPython.display import Image\n",
    "\n",
    "# Define the feature names\n",
    "feature_names = ['feature' + str(i) for i in range(1, 25)]\n",
    "\n",
    "# Export the decision tree as DOT file\n",
    "dot_data = export_graphviz(dt, out_file=None, feature_names=feature_names, filled=True, rounded=True)\n",
    "\n",
    "# Create a graph from DOT data\n",
    "graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "\n",
    "# Generate the image file\n",
    "graph.write_png(\"decision_tree.png\")\n",
    "\n",
    "# Display the decision tree\n",
    "Image(graph.create_png())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##  An ensemble of decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#--------  tree_ensemble\n",
    "# A function that builds an ensemble of trees\n",
    "# Input: \n",
    "#      df_train  (Panda dataframe of the training set)\n",
    "#      x_test    (Array of predictors in training set)\n",
    "#      y_test    (Array of binary responses in training set)\n",
    "#      num_trees (Number of decision trees in the ensemble)\n",
    "#      yvar      (Target variable)\n",
    "#      max_depth (Depth of each decision tree)\n",
    "# Returns: \n",
    "#      tree_array (Array of the build trees)\n",
    "\n",
    "def tree_ensemble(df_train, x_test, y_test, num_trees, yvar, max_depth):\n",
    "    tree_array = []\n",
    "        \n",
    "    for i in range(num_trees):\n",
    "        # Randomly sample (with replacment) \n",
    "        train_set = df_train.sample(n=df_train.shape[0], replace=True)\n",
    "        y_train = train_set[yvar].values\n",
    "        train_set_predictors = train_set.drop(drop_var, axis=1)\n",
    "        x_train = train_set_predictors.values\n",
    "\n",
    "        # Build the CART tree\n",
    "        ct = tree.DecisionTreeClassifier(max_depth=max_depth, criterion='gini')\n",
    "\n",
    "        # Fit the model\n",
    "        clf = ct.fit(x_train, y_train)\n",
    "\n",
    "        # Ensemble the models\n",
    "        tree_array.append(clf)\n",
    "\n",
    "        # Accuracy\n",
    "        training_accuracy = clf.score(x_train, y_train)\n",
    "        test_accuracy = clf.score(x_test, y_test)\n",
    "        \n",
    "        return tree_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#--------  random_classifier\n",
    "# A function that builds a random classifier\n",
    "# Input: \n",
    "#      x_test    (Array of predictors in training set)\n",
    "#      y_test    (Array of binary responses in training set)\n",
    "#      trees     (Decision trees)\n",
    "# Returns: \n",
    "#      accuracy  (Test accuracy)\n",
    "\n",
    "def random_classifier(x_test, y_test, trees):\n",
    "    y_predict = np.zeros((len(y_test),1))\n",
    "    \n",
    "    for j in range(x_test.shape[0]):\n",
    "        tree = np.random.choice(trees)\n",
    "        y_predict[j] = tree.predict(x_test[j,:].reshape(1,-1)) # predict on a single sample\n",
    "    \n",
    "    accuracy = np.mean(y_test == y_predict) \n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#--------  majority_classifier\n",
    "# A function that builds a majority vote classifier\n",
    "# Input: \n",
    "#      x_test    (Array of predictors in training set)\n",
    "#      y_test    (Array of binary responses in training set)\n",
    "#      trees     (Decision trees)\n",
    "# Returns: \n",
    "#      accuracy  (Test accuracy)\n",
    "\n",
    "def majority_classifier(x_test, y_test, trees):\n",
    "    y_counts = np.zeros((len(y_test), 2))\n",
    "\n",
    "    for index, tree in enumerate(trees):\n",
    "        y_predict = tree.predict(x_test)\n",
    "        y_counts[y_predict==0,0] += 1\n",
    "        y_counts[y_predict==1,1] += 1\n",
    "    \n",
    "    y_predict = y_counts.argmax(axis=1)\n",
    "    return np.mean(y_test == y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load the train and test data\n",
    "train_data = np.loadtxt('dataset_5_train.txt', delimiter=',')\n",
    "test_data = np.loadtxt('dataset_5_test.txt', delimiter=',')\n",
    "\n",
    "# Split the features and target variable\n",
    "X_train = train_data[:, :-1]\n",
    "y_train = train_data[:, -1]\n",
    "X_test = test_data[:, :-1]\n",
    "y_test = test_data[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Import the required libraries\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Fit a single decision tree\n",
    "max_depth = 3  # Specify the maximum depth for the decision tree\n",
    "dt = DecisionTreeClassifier(max_depth=max_depth)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Fit a random forest ensemble\n",
    "num_trees = 100\n",
    "tree_array = []\n",
    "\n",
    "for i in range(num_trees):\n",
    "    # Randomly sample (with replacement)\n",
    "    train_set = train_data[np.random.choice(train_data.shape[0], size=train_data.shape[0], replace=True)]\n",
    "    y_train_subset = train_set[:, -1]\n",
    "    X_train_subset = train_set[:, :-1]\n",
    "    \n",
    "    # Build the CART tree\n",
    "    ct = DecisionTreeClassifier(max_depth=max_depth, criterion='gini')\n",
    "\n",
    "    # Fit the model\n",
    "    clf = ct.fit(X_train_subset, y_train_subset)\n",
    "\n",
    "    # Ensemble the models\n",
    "    tree_array.append(clf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model selection (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Random classifier\n",
    "random_accuracy = random_classifier(X_test, y_test, tree_array)\n",
    "\n",
    "# Majority classifier\n",
    "majority_accuracy = majority_classifier(X_test, y_test, tree_array)\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=num_trees, max_depth=max_depth)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_accuracy = rf.score(X_test, y_test)\n",
    "\n",
    "print(\"Random Classifier Accuracy:\", random_accuracy)\n",
    "print(\"Majority Classifier Accuracy:\", majority_accuracy)\n",
    "print(\"Random Forest Accuracy:\", rf_accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}